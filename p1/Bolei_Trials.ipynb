{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>feat_001</th>\n",
       "      <th>feat_002</th>\n",
       "      <th>feat_003</th>\n",
       "      <th>feat_004</th>\n",
       "      <th>feat_005</th>\n",
       "      <th>feat_006</th>\n",
       "      <th>feat_007</th>\n",
       "      <th>feat_008</th>\n",
       "      <th>feat_009</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_248</th>\n",
       "      <th>feat_249</th>\n",
       "      <th>feat_250</th>\n",
       "      <th>feat_251</th>\n",
       "      <th>feat_252</th>\n",
       "      <th>feat_253</th>\n",
       "      <th>feat_254</th>\n",
       "      <th>feat_255</th>\n",
       "      <th>feat_256</th>\n",
       "      <th>gap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 258 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  feat_001  feat_002  \\\n",
       "0  c1ccc(o1)-c1ccc(s1)-c1cnc(-c2scc3[se]ccc23)c2n...       0.0       0.0   \n",
       "1  C1=CC=C(C1)c1cc2ncc3c4[SiH2]C=Cc4ncc3c2c2=C[Si...       1.0       0.0   \n",
       "2  [nH]1c-2c([SiH2]c3cc(-c4scc5C=CCc45)c4nsnc4c-2...       1.0       0.0   \n",
       "3  [nH]1c2-c3occc3Cc2c2c1cc(-c1cccc3=C[SiH2]C=c13...       1.0       0.0   \n",
       "4     c1cnc2c3oc4cc(-c5ncncn5)c5nsnc5c4c3c3cocc3c2c1       0.0       0.0   \n",
       "\n",
       "   feat_003  feat_004  feat_005  feat_006  feat_007  feat_008  feat_009  ...   \\\n",
       "0       0.0       0.0       1.0       0.0       1.0       0.0       0.0  ...    \n",
       "1       0.0       0.0       1.0       0.0       1.0       0.0       0.0  ...    \n",
       "2       0.0       0.0       1.0       1.0       1.0       0.0       0.0  ...    \n",
       "3       0.0       0.0       1.0       1.0       1.0       0.0       0.0  ...    \n",
       "4       0.0       0.0       1.0       0.0       1.0       0.0       0.0  ...    \n",
       "\n",
       "   feat_248  feat_249  feat_250  feat_251  feat_252  feat_253  feat_254  \\\n",
       "0       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "1       1.0       0.0       0.0       1.0       0.0       0.0       0.0   \n",
       "2       1.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "3       1.0       0.0       0.0       0.0       1.0       0.0       0.0   \n",
       "4       1.0       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "   feat_255  feat_256   gap  \n",
       "0       0.0       0.0  1.19  \n",
       "1       0.0       0.0  1.60  \n",
       "2       0.0       0.0  1.49  \n",
       "3       0.0       0.0  1.36  \n",
       "4       0.0       0.0  1.98  \n",
       "\n",
       "[5 rows x 258 columns]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read in train and test as Pandas DataFrames\n",
    "\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# names2=['feat_002', 'feat_003', 'feat_004', 'feat_008', 'feat_009', 'feat_010', 'feat_011', 'feat_012', 'feat_013', 'feat_014', 'feat_015', 'feat_016', 'feat_017', 'feat_018', 'feat_019', 'feat_020', 'feat_021', 'feat_022', 'feat_023', 'feat_024', 'feat_026', 'feat_027', 'feat_028', 'feat_029', 'feat_030', 'feat_031', 'feat_032', 'feat_033', 'feat_034', 'feat_035', 'feat_036', 'feat_038', 'feat_039', 'feat_040', 'feat_041', 'feat_042', 'feat_043', 'feat_045', 'feat_046', 'feat_047', 'feat_048', 'feat_049', 'feat_050', 'feat_051', 'feat_052', 'feat_053', 'feat_054', 'feat_055', 'feat_056', 'feat_057', 'feat_058', 'feat_059', 'feat_060', 'feat_061', 'feat_062', 'feat_063', 'feat_064', 'feat_065', 'feat_066', 'feat_067', 'feat_070', 'feat_071', 'feat_073', 'feat_074', 'feat_075', 'feat_076', 'feat_077', 'feat_078', 'feat_079', 'feat_080', 'feat_081', 'feat_082', 'feat_083', 'feat_084', 'feat_085', 'feat_086', 'feat_088', 'feat_089', 'feat_091', 'feat_092', 'feat_093', 'feat_094', 'feat_095', 'feat_096', 'feat_097', 'feat_098', 'feat_099', 'feat_100', 'feat_101', 'feat_103', 'feat_104', 'feat_105', 'feat_106', 'feat_107', 'feat_108', 'feat_109', 'feat_110', 'feat_111', 'feat_112', 'feat_113', 'feat_114', 'feat_115', 'feat_116', 'feat_117', 'feat_118', 'feat_120', 'feat_121', 'feat_122', 'feat_124', 'feat_125', 'feat_127', 'feat_128', 'feat_129', 'feat_130', 'feat_131', 'feat_133', 'feat_134', 'feat_135', 'feat_136', 'feat_137', 'feat_138', 'feat_139', 'feat_140', 'feat_141', 'feat_142', 'feat_143', 'feat_144', 'feat_145', 'feat_146', 'feat_147', 'feat_148', 'feat_149', 'feat_150', 'feat_151', 'feat_152', 'feat_153', 'feat_154', 'feat_155', 'feat_156', 'feat_157', 'feat_158', 'feat_159', 'feat_160', 'feat_161', 'feat_162', 'feat_163', 'feat_164', 'feat_165', 'feat_166', 'feat_167', 'feat_168', 'feat_169', 'feat_170', 'feat_171', 'feat_172', 'feat_174', 'feat_175', 'feat_177', 'feat_178', 'feat_179', 'feat_180', 'feat_181', 'feat_182', 'feat_183', 'feat_184', 'feat_185', 'feat_186', 'feat_188', 'feat_189', 'feat_190', 'feat_191', 'feat_192', 'feat_193', 'feat_194', 'feat_195', 'feat_197', 'feat_198', 'feat_201', 'feat_202', 'feat_203', 'feat_204', 'feat_205', 'feat_206', 'feat_207', 'feat_209', 'feat_210', 'feat_211', 'feat_212', 'feat_213', 'feat_214', 'feat_215', 'feat_216', 'feat_217', 'feat_219', 'feat_220', 'feat_221', 'feat_222', 'feat_223', 'feat_224', 'feat_227', 'feat_228', 'feat_229', 'feat_230', 'feat_231', 'feat_232', 'feat_233', 'feat_234', 'feat_235', 'feat_236', 'feat_237', 'feat_238', 'feat_239', 'feat_240', 'feat_241', 'feat_242', 'feat_244', 'feat_245', 'feat_246', 'feat_247', 'feat_249', 'feat_250', 'feat_253', 'feat_254', 'feat_255', 'feat_256',\n",
    "       #'feat_199','feat_200','feat_005']#'feat_252','feat_226','feat_208','feat_176','feat_132','feat_044','feat_007']\n",
    "\n",
    "df_train_short = df_train#.drop(names2, axis=1)\n",
    "df_test_short = df_test#.drop(names2, axis=1)\n",
    "#store gap values\n",
    "Y_train = df_train_short.gap.values\n",
    "#row where testing examples start\n",
    "test_idx = df_train_short.shape[0]\n",
    "#delete 'Id' column\n",
    "df_test_short = df_test_short.drop(['Id'], axis=1)\n",
    "#delete 'gap' column\n",
    "df_train_short = df_train_short.drop(['gap'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_train2=df_train.drop(['smiles'],axis=1)\n",
    "# smiles=df_train['smiles']\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(df_train2)\n",
    "# df_train2=scaler.transform(df_train2) \n",
    "# df_train2=pd.DataFrame(data=df_train2[0:,0:])\n",
    "# #               index=df_train2[1:,0],\n",
    "# #               columns=df_train2[0,1:])\n",
    "# df_train2.insert(0, 'smiles', smiles)\n",
    "# df_train2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(824230, 256)\n",
      "(1000000, 256)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_test_short2 = df_test_short.drop(['smiles'], axis=1)\n",
    "df_train_short2 = df_train_short.drop(['smiles'], axis=1)\n",
    "vals_test = df_test_short2.values\n",
    "vals_train = df_train_short2.values\n",
    "print(vals_test.shape)\n",
    "#Divide the matrix into 5 parts\n",
    "Test_num = 5;\n",
    "piecesize = int(len(df_train)/5);\n",
    "X_train_train = vals_train#[:4*piecesize]\n",
    "X_train_test = vals_train[4*piecesize:]\n",
    "Y_train_train =  Y_train#[:4*piecesize]\n",
    "Y_train_test = Y_train[4*piecesize:]\n",
    "# X_train_train = vals_train[piecesize:]\n",
    "# X_train_test = vals_train[:piecesize]\n",
    "# Y_train_train =  Y_train[piecesize:]\n",
    "# Y_train_test = Y_train[:piecesize]\n",
    "# [length,num] = X_train_test.shape\n",
    "# for i in range(num):   \n",
    "#     print(np.sum(X_train_test[:,i])/800000,i+1)\n",
    "# print(X_train_train.shape)\n",
    "# import math\n",
    "\n",
    "# print(X_train_train.shape)\n",
    "# for i in range(num):\n",
    "#     aver1 = []\n",
    "#     aver0 = []\n",
    "#     for j in range(length):\n",
    "#         if X_train_train[j][i]==1:\n",
    "#             aver1.append(Y_train_train[j])\n",
    "#         else:\n",
    "#             aver0.append(Y_train_train[j])\n",
    "#     print('Difference made by feature', i, np.mean(aver1)-np.mean(aver0))\n",
    "print(X_train_train.shape)\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 14)\n",
      "Difference made by feature 1 -0.232546819379\n",
      "Difference made by feature 2 -0.3530780789\n",
      "Difference made by feature 3 -0.0680799895291\n",
      "Difference made by feature 4 -0.0554220105008\n",
      "Difference made by feature 5 -0.0559530100721\n",
      "Difference made by feature 6 -0.065883929691\n",
      "Difference made by feature 7 -0.326803901843\n",
      "Difference made by feature 8 -0.312452503166\n",
      "Difference made by feature 9 0.156215611268\n",
      "Difference made by feature 10 -0.0735347693701\n",
      "Difference made by feature 11 -0.159369141931\n",
      "Difference made by feature 12 -0.226978771906\n",
      "Difference made by feature 13 -0.326803901843\n",
      "Difference made by feature 14 0.320232580321\n"
     ]
    }
   ],
   "source": [
    "X_train_train = np.delete(X_train_train, [1,2,4,7,9,13,15,20,24,27,26,25,16,22], 1)\n",
    "X_train_test = np.delete(X_train_test, [1,2,4,7,9,13,15,20,24,27,26,25,16,22], 1)\n",
    "[length,num] = X_train_test.shape\n",
    "\n",
    "print(X_train_train.shape)\n",
    "for i in range(num):\n",
    "    aver1 = []\n",
    "    aver0 = []\n",
    "    for j in range(length):\n",
    "        if X_train_train[j][i]==1:\n",
    "            aver1.append(Y_train_train[j])\n",
    "        else:\n",
    "            aver0.append(Y_train_train[j])\n",
    "    print('Difference made by feature', i+1, np.mean(aver1)-np.mean(aver0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features: (800000, 31)\n",
      "Train features: (200000, 31)\n"
     ]
    }
   ],
   "source": [
    "#Normalisation\n",
    "X_train_train = preprocessing.scale(X_train_train.T)\n",
    "X_train_train = X_train_train.T\n",
    "X_train_test = preprocessing.scale(X_train_test.T)\n",
    "X_train_test = X_train_test.T\n",
    "\n",
    "print (\"Train features:\", X_train_train.shape)\n",
    "print (\"Train features:\", X_train_test.shape)\n",
    "\n",
    "#Transfer from 0,1 to 1,2\n",
    "[num1,feature1]=X_train_train.shape\n",
    "for i in range(num1):\n",
    "    for j in range(feature1):\n",
    "        X_train_train[i][j]+=2\n",
    "        \n",
    "[num2,feature2]=X_train_test.shape\n",
    "for i in range(num2):\n",
    "    for j in range(feature2):      \n",
    "        X_train_test[i][j]+=2\n",
    "\n",
    "# X_train_train = X_train_train\n",
    "# X_train_train = X_train_train.T\n",
    "# X_train_test = [x + 1 for x in X_train_test]\n",
    "# X_train_test = X_train_test.T\n",
    "X_train_train1 = X_train_train[:]\n",
    "X_train_test1 = X_train_test[:]\n",
    "print(X_train_train)\n",
    "print(X_train_test)\n",
    "print (\"Train features:\", X_train_train.shape)\n",
    "print (\"Train features:\", X_train_test.shape)\n",
    "\n",
    "#Temporal\n",
    "X_train_train = X_train_train1[:]\n",
    "X_train_test = X_train_test1[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Polynomial_basis(X,n):\n",
    "    N=len(X)\n",
    "    \n",
    "    \n",
    "    M = np.ones(X.shape)\n",
    "    M = M.T\n",
    "    for i in range(1,n+1):\n",
    "        M = np.vstack([M,np.power(X,i).T])\n",
    "    return M.T\n",
    "\n",
    "# Polynomial_basis(X_train_test,1).shape\n",
    "\n",
    "def Sin_basis(X,n):\n",
    "    N=len(X)\n",
    "    \n",
    "    M = np.ones(X.shape)\n",
    "    M = M.T\n",
    "    for i in range(1,n+1):\n",
    "        M = np.vstack([M,np.sin(3.141592/i*X).T])\n",
    "    return M.T\n",
    "\n",
    "# Polynomial_basis(X_train_test,1).shape\n",
    "\n",
    "def Cross(X,num):\n",
    "    [length,feature] = X.shape\n",
    "    for k in range(1,num):\n",
    "        print(k)\n",
    "        for i in range(0,feature-k):\n",
    "            temp = np.zeros(length)\n",
    "            for j in range(0,length):\n",
    "                temp[j] = X[j,i]*X[j,i+k]\n",
    "            X = np.vstack([X.T,temp.T])\n",
    "            X = X.T\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "(200000, 105)\n",
      "(800000, 105)\n"
     ]
    }
   ],
   "source": [
    "X_train_train = Cross(X_train_train,14)\n",
    "X_train_test = Cross(X_train_test,14)\n",
    "print(X_train_test.shape)\n",
    "print(X_train_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 155)\n",
      "(800000, 155)\n",
      "[[ 1.          1.          1.         ...,  0.67820069  1.4744898\n",
      "   1.4744898 ]\n",
      " [ 1.          1.          1.         ...,  1.4744898   1.4744898\n",
      "   0.67820069]\n",
      " [ 1.          1.          1.         ...,  5.97530864  0.16735537\n",
      "   0.16735537]\n",
      " ..., \n",
      " [ 1.          1.          1.         ...,  2.50694444  0.39889197\n",
      "   0.39889197]\n",
      " [ 1.          1.          1.         ...,  1.91715976  0.52160494\n",
      "   0.52160494]\n",
      " [ 1.          1.          1.         ...,  4.41        0.22675737\n",
      "   0.22675737]]\n"
     ]
    }
   ],
   "source": [
    "order = 4\n",
    "X_train_train = Polynomial_basis(X_train_train,order)\n",
    "X_train_test = Polynomial_basis(X_train_test,order)\n",
    "print(X_train_test.shape)\n",
    "print(X_train_train.shape)\n",
    "print(X_train_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 279)\n",
      "(800000, 279)\n"
     ]
    }
   ],
   "source": [
    "order = 8\n",
    "X_train_train = Sin_basis(X_train_train,order)\n",
    "X_train_test = Sin_basis(X_train_test,order)\n",
    "print(X_train_test.shape)\n",
    "print(X_train_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RMSE(Y,Y_Pred):\n",
    "    N=len(Y)\n",
    "    Err=0\n",
    "    for i in range(N):\n",
    "        Err=Err+(Y[i]-Y_Pred[i])**2\n",
    "    Err=(1./N*Err)**(1./2.)\n",
    "    return Err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800000, 105)\n",
      "2.9150469303131104\n",
      "[ 0.06114988  0.21182095  0.33255247 -0.03063072  0.35194557 -0.450504\n",
      " -0.43316653  0.02429488 -0.00630862 -0.31823367  0.52936928 -0.500504\n",
      " -0.45769904  0.56182095 -0.080504   -0.23769904 -0.23805443  0.08194557\n",
      "  0.09297614 -0.24316653  0.29800832 -0.02656456 -0.220504    0.02800832\n",
      "  0.33384554 -0.6537073  -0.45744753 -0.04834562  0.07691038 -0.28615446\n",
      " -0.13557194 -0.04926882 -0.02570512 -0.49744753 -0.01805443  0.05843015\n",
      "  0.40255247 -0.23315731 -0.2113196   0.00429488 -0.01156985  0.09194557\n",
      " -0.07885012  0.14683347  0.25574481  0.84230096  0.00667688 -0.21805443\n",
      "  0.20429488]\n",
      "0.301199100325\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression \n",
    "print(X_train_train.shape)\n",
    "LR = LinearRegression()\n",
    "BT=time.time()\n",
    "LR.fit(X_train_train, Y_train_train)\n",
    "ET=time.time()\n",
    "LR_pred = LR.predict(X_train_test)\n",
    "print (ET-BT)\n",
    "print((LR_pred-Y_train_test)[1:50])\n",
    "print(RMSE(LR_pred,Y_train_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.066691875457764\n",
      "[ 0.09335235  0.2112105   0.32618493 -0.04610866  0.34794456 -0.46706054\n",
      " -0.43106467 -0.0059579   0.0131704  -0.25558436  0.51389134 -0.51706054\n",
      " -0.44206101  0.5612105  -0.09706054 -0.22206101 -0.24205544  0.07794456\n",
      "  0.01372464 -0.24106467  0.29120388 -0.02509359 -0.23706054  0.02120388\n",
      "  0.28359475 -0.61880405 -0.46381507 -0.02983228  0.05491431 -0.33640525\n",
      " -0.13016398 -0.09549982 -0.0559579  -0.50381507 -0.02205544  0.09689482\n",
      "  0.39618493 -0.15228009 -0.24810362 -0.0259579   0.02689482  0.08794456\n",
      " -0.04664765  0.14893533  0.22161188  0.85793899  0.02143048 -0.22205544\n",
      "  0.1740421 ]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  1.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      "0.297478628687\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Regression\n",
    "RF = RandomForestRegressor()\n",
    "BT=time.time()\n",
    "RF.fit(X_train_train, Y_train_train)\n",
    "ET=time.time()\n",
    "RF_pred = RF.predict(X_train_test)\n",
    "print (ET-BT)\n",
    "print((RF_pred-Y_train_test)[1:50])\n",
    "print(X_train_test[45,:])\n",
    "print(RMSE(RF_pred,Y_train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.53357696533203\n",
      "0.301494373694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Bolei/anaconda/lib/python3.5/site-packages/sklearn/linear_model/coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net Regression\n",
    "EN=ElasticNetCV(n_jobs=-3)\n",
    "BT=time.time()\n",
    "EN.fit(X_train_train, Y_train_train)\n",
    "ET=time.time()\n",
    "EN_pred = EN.predict(X_train_test)\n",
    "print (ET-BT)\n",
    "print(RMSE(EN_pred,Y_train_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20961594581604004\n",
      "0.407544170423\n"
     ]
    }
   ],
   "source": [
    "# Elastic Net Regression\n",
    "MN=ElasticNet()\n",
    "BT=time.time()\n",
    "MN.fit(X_train_train, Y_train_train)\n",
    "ET=time.time()\n",
    "MN_pred = MN.predict(X_train_test)\n",
    "print (ET-BT)\n",
    "print(RMSE(MN_pred,Y_train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print ('EN Score =',EN.score(X_train_train,Y_train_train))\n",
    "# print ('RF Score =',RF.score(X_train_train,Y_train_train))\n",
    "# print ('LR Score =',LR.score(X_train_train,Y_train_train))\n",
    "# print ('MN Score =',MN.score(X_train_train,Y_train_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'write_to_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-abc3903c6a02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwrite_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sample2.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRF_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'write_to_file' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000000, 256)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.272676539956\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "clf = tree.DecisionTreeRegressor(max_depth=44,max_features=None,max_leaf_nodes=None)\n",
    "clf = clf.fit(X_train_train,Y_train_train)\n",
    "DT_pred = clf.predict(X_train_test)\n",
    "print(RMSE(DT_pred,Y_train_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_file(filename, predictions):\n",
    "    with open(filename, \"w\") as f:\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i,p in enumerate(predictions):\n",
    "            f.write(str(i+1) + \",\" + str(p) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DT_pred = clf.predict(vals_test)\n",
    "write_to_file(\"Try4.csv\", DT_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.276749681374\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neural_network\n",
    "sample = neural_network.MLPRegressor(hidden_layer_sizes=(100, ),alpha=0.0001)\n",
    "sample = sample.fit(X_train_train,Y_train_train)\n",
    "MLP_pred = sample.predict(X_train_test)\n",
    "print(RMSE(MLP_pred,Y_train_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.275225791025\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
