{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#Functions used in this practical\n",
    "\n",
    "#Define the function calculating accuracy\n",
    "def accuracy(Y,Y_pred):\n",
    "    total = len(Y)\n",
    "    correct = 0\n",
    "    cor = np.zeros([15,1])\n",
    "    count = np.zeros([15,1])\n",
    "    countpred = np.zeros([15,1])\n",
    "    for i in xrange(total):\n",
    "        count[Y[i]] += 1\n",
    "        countpred[Y_pred[i]] += 1\n",
    "        if Y[i]==Y_pred[i]:\n",
    "            cor[Y[i]] += 1           \n",
    "        if Y[i]==Y_pred[i]:\n",
    "            correct += 1\n",
    "    \n",
    "    return float(correct)/float(total), cor/count, cor/countpred\n",
    "\n",
    "#Normalise the input features\n",
    "def normalise(X_train):\n",
    "    [length,feature] = X_train.shape\n",
    "    X_train_new = np.zeros([length,feature])\n",
    "    for i in xrange(feature):\n",
    "        summa = 0\n",
    "        for j in xrange(length):\n",
    "            summa += X_train[j,i]\n",
    "        print summa\n",
    "        for j in xrange(length):   \n",
    "            X_train_new[j,i] = float(X_train[j,i])/float(summa)\n",
    "    return X_train_new\n",
    "\n",
    "#Drop some features\n",
    "#These not in testing files\n",
    "def throwredundant(X_train):\n",
    "    aa = [6,54,91] #never appears\n",
    "    bb = [6,54,91,0,70,76,78,80,87,90,126]#appear only one time\n",
    "    cc = [6,54,91,0,70,76,78,80,87,90,126,44,71,84,85,86]#appear less than 5 times\n",
    "    dd = [6,54,91,0,70,76,78,80,87,90,126,44,71,84,85,86,14,16,22,31,37,42,48,58,64,65,67,74,79,83,117]\n",
    "   \n",
    "    [length,feature] = X_train.shape\n",
    "    X_train_new = np.zeros([length,feature-len(cc)])\n",
    "    count = 0\n",
    "    for i in xrange(feature):\n",
    "        if i not in cc:\n",
    "            for j in xrange(length):\n",
    "                X_train_new[j,count] = X_train[j,i]\n",
    "            count += 1\n",
    "    return X_train_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from classification_starter2 import *\n",
    "\n",
    "## The following function does the feature extraction, learning, and prediction\n",
    "train_dir = \"train\"\n",
    "test_dir = \"test\"\n",
    "outputfile = \"mypredictions.csv\"  # feel free to change this or take it as an argument\n",
    "\n",
    "# TODO put the names of the feature functions you've defined above in this list\n",
    "\n",
    "#Use level_1,level_2, level_3, level_4 as different feature levels\n",
    "ffs = [first_last_system_call_feats, level_1]\n",
    "from classification_starter2 import *\n",
    "# extract features\n",
    "print (\"extracting training features...\")\n",
    "X_train,global_feat_dict,t_train,train_ids = extract_feats(ffs, train_dir)\n",
    "print (\"done extracting training features\")\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3086, 102)\n"
     ]
    }
   ],
   "source": [
    "#Drop the redundant features\n",
    "X_train = throwredundant(X_train)\n",
    "\n",
    "#Separate training files into training and testing part\n",
    "sepa = 600\n",
    "X_train2 = X_train[1:sepa,:]\n",
    "X_train1 = X_train[sepa+1:,:]\n",
    "t_train2 = t_train[1:sepa,]\n",
    "t_train1 = t_train[sepa+1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from classification_starter2 import *\n",
    "\n",
    "# TODO train here, and learn your classification parameters\n",
    "print (\"learning...\")\n",
    "LR=LogisticRegression( multi_class = 'ovr')\n",
    "BT=time.time()\n",
    "LR.fit(X_train1, t_train1)\n",
    "ET=time.time()\n",
    "print (\"done learning\")\n",
    "print ET-BT\n",
    "\n",
    "# TODO make predictions on text data and write them out\n",
    "print (\"making predictions...\")\n",
    "LR_pred = LR.predict(X_train2)\n",
    "print (\"done making predictions\")\n",
    "print ()\n",
    "accuracy(t_train2,LR_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neural networks\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from classification_starter2 import *\n",
    "\n",
    "# TODO train here, and learn your classification parameters\n",
    "print (\"learning...\")\n",
    "MLP=MLPClassifier(hidden_layer_sizes=(200,),activation='logistic')\n",
    "BT=time.time()\n",
    "MLP.fit(X_train1, t_train1)\n",
    "ET=time.time()\n",
    "print (\"done learning\")\n",
    "print ET-BT\n",
    "\n",
    "# TODO make predictions on text data and write them out\n",
    "print (\"making predictions...\")\n",
    "MLP_pred = MLP.predict(X_train2)\n",
    "print (\"done making predictions\")\n",
    "print ()\n",
    "accuracy(t_train2,MLP_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from classification_starter2 import *\n",
    "\n",
    "# TODO train here, and learn your classification parameters\n",
    "print (\"learning...\")\n",
    "RF=RandomForestClassifier(n_estimators=500,criterion = 'gini',max_depth=100,class_weight = None)#'balanced')\n",
    "BT=time.time()\n",
    "RF.fit(X_train, t_train)\n",
    "ET=time.time()\n",
    "print (\"done learning\")\n",
    "print ET-BT\n",
    "\n",
    "# TODO make predictions on text data and write them out\n",
    "print (\"making predictions...\")\n",
    "RF_pred = RF.predict(X_train2)\n",
    "print (\"done making predictions\")\n",
    "print ()\n",
    "accuracy(t_train2,RF_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting test features...\n",
      "done extracting test features\n",
      "()\n"
     ]
    }
   ],
   "source": [
    "# get rid of training data and load test data\n",
    "from classification_starter2 import *\n",
    "del X_train\n",
    "del t_train\n",
    "del train_ids\n",
    "print (\"extracting test features...\")\n",
    "X_test,_,t_ignore,test_ids = extract_feats(ffs, test_dir, global_feat_dict=global_feat_dict)\n",
    "print (\"done extracting test features\")\n",
    "print ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making predictions...\n",
      "done making predictions\n",
      "()\n",
      "writing predictions...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "#Random forest\n",
    "# TODO make predictions on text data and write them out\n",
    "X_test = throwredundant(X_test)\n",
    "# X_test = normalise(X_test)\n",
    "print (\"making predictions...\")\n",
    "RF_pred = RF.predict(X_test)\n",
    "print (\"done making predictions\")\n",
    "print ()\n",
    "preds = RF_pred\n",
    "print (\"writing predictions...\")\n",
    "util.write_predictions(preds, test_ids, outputfile)\n",
    "print (\"done!\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
